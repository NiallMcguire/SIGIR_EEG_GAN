{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "r-DThd_lj_zI"
   },
   "source": [
    "# Machine Learning with PyTorch and Scikit-Learn  \n",
    "# -- Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGIyW3DVj_zN"
   },
   "source": [
    "## Package version checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy7MuRTxj_zO"
   },
   "source": [
    "Add folder to path in order to load from the check_packages.py script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:20.934574Z",
     "end_time": "2023-11-20T13:22:21.138151Z"
    },
    "id": "304b_-gUj_zP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6n4xVBej_zR"
   },
   "source": [
    "Check recommended package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:20.950373Z",
     "end_time": "2023-11-20T13:22:21.140710Z"
    },
    "id": "sJR2feQ9j_zR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9XN3qSZ6Kbr",
    "outputId": "44d35360-41f2-4eb5-adcf-27ece849b685",
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:20.966029Z",
     "end_time": "2023-11-20T13:22:23.339775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VXasfQIW3XeR",
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:23.343324Z",
     "end_time": "2023-11-20T13:22:23.877137Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzJjZmH9j_zV"
   },
   "source": [
    "## Train the DCGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:23.877137Z",
     "end_time": "2023-11-20T13:22:24.312680Z"
    },
    "id": "Ndx7OkPWj_zV"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "image_path = './'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path,\n",
    "                                           train=True,\n",
    "                                           transform=transform,\n",
    "                                           download=True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "## Set up the dataset\n",
    "from torch.utils.data import DataLoader\n",
    "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.312680Z",
     "end_time": "2023-11-20T13:22:24.445506Z"
    },
    "id": "AUumFjJ7j_zX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataLoader 'data_loader' set up as in the previous examples\n",
    "\n",
    "# Use a for loop to iterate through the DataLoader\n",
    "for batch_idx, (images, labels) in enumerate(mnist_dl):\n",
    "    if batch_idx == 0:\n",
    "        # Extract the first image from the first batch\n",
    "        first_image = images[0][0].numpy()  # Assuming grayscale images\n",
    "\n",
    "        # Create a Matplotlib figure and axis\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # Display the image on the axis\n",
    "        ax.imshow(first_image, cmap='gray')\n",
    "\n",
    "        # Optionally, you can add a title or other customizations\n",
    "        ax.set_title(f\"Label: {labels[0].item()}\")\n",
    "        ax.axis('off')  # Turn off axis labels and ticks\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    else:\n",
    "        break  # Exit the loop after processing the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.445506Z",
     "end_time": "2023-11-20T13:22:24.476821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.460635Z",
     "end_time": "2023-11-20T13:22:24.476821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.476821Z",
     "end_time": "2023-11-20T13:22:24.492463Z"
    },
    "id": "xfRCCVtNj_zY"
   },
   "outputs": [],
   "source": [
    "z_size = 100\n",
    "image_size = (28, 28)\n",
    "n_filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.492463Z",
     "end_time": "2023-11-20T13:22:24.532250Z"
    },
    "id": "PzQA8U6ej_zY"
   },
   "outputs": [],
   "source": [
    "## Loss function and optimizers:\n",
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.517237Z",
     "end_time": "2023-11-20T13:22:24.532250Z"
    },
    "id": "rqEIEy4aj_zZ"
   },
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size, 1, 1)*2 - 1\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size, 1, 1)\n",
    "    return input_z\n",
    "\n",
    "mode_z = 'uniform'\n",
    "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "\n",
    "def create_samples(g_model, input_z):\n",
    "    g_output = g_model(input_z)\n",
    "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
    "    return (images+1)/2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "Tbgj_nyfj_zZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.527734Z",
     "end_time": "2023-11-20T13:22:24.541904Z"
    },
    "id": "nJMlmA7Gj_za"
   },
   "outputs": [],
   "source": [
    "noise = create_noise(64, 100, \"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.541904Z",
     "end_time": "2023-11-20T13:22:24.603613Z"
    },
    "id": "evGO6Elnj_za"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.4649]],\n\n        [[ 0.9821]],\n\n        [[ 0.6806]],\n\n        [[-0.1813]],\n\n        [[ 0.0300]],\n\n        [[ 0.3185]],\n\n        [[ 0.4067]],\n\n        [[-0.8644]],\n\n        [[-0.9831]],\n\n        [[ 0.7897]],\n\n        [[-0.7247]],\n\n        [[-0.3738]],\n\n        [[ 0.8620]],\n\n        [[-0.2410]],\n\n        [[ 0.8508]],\n\n        [[-0.3005]],\n\n        [[-0.1327]],\n\n        [[-0.4997]],\n\n        [[ 0.6467]],\n\n        [[ 0.8523]],\n\n        [[-0.7129]],\n\n        [[-0.3407]],\n\n        [[-0.2592]],\n\n        [[ 0.4902]],\n\n        [[-0.8490]],\n\n        [[ 0.5275]],\n\n        [[ 0.1656]],\n\n        [[-0.0287]],\n\n        [[ 0.7964]],\n\n        [[ 0.4055]],\n\n        [[-0.3786]],\n\n        [[-0.2544]],\n\n        [[ 0.0872]],\n\n        [[ 0.3750]],\n\n        [[ 0.1111]],\n\n        [[-0.8907]],\n\n        [[-0.1392]],\n\n        [[-0.2259]],\n\n        [[-0.4351]],\n\n        [[-0.8971]],\n\n        [[ 0.0421]],\n\n        [[ 0.4082]],\n\n        [[-0.9173]],\n\n        [[-0.2362]],\n\n        [[-0.2658]],\n\n        [[-0.4302]],\n\n        [[ 0.6400]],\n\n        [[ 0.6987]],\n\n        [[-0.1364]],\n\n        [[-0.1172]],\n\n        [[ 0.5424]],\n\n        [[ 0.3534]],\n\n        [[-0.0343]],\n\n        [[-0.5258]],\n\n        [[-0.7916]],\n\n        [[-0.7895]],\n\n        [[ 0.0045]],\n\n        [[-0.3724]],\n\n        [[ 0.7112]],\n\n        [[-0.0805]],\n\n        [[ 0.3828]],\n\n        [[-0.7012]],\n\n        [[ 0.3276]],\n\n        [[ 0.6068]],\n\n        [[-0.3766]],\n\n        [[ 0.9901]],\n\n        [[ 0.1628]],\n\n        [[-0.9811]],\n\n        [[ 0.4741]],\n\n        [[ 0.9126]],\n\n        [[-0.1553]],\n\n        [[-0.6518]],\n\n        [[-0.2244]],\n\n        [[-0.8023]],\n\n        [[-0.2863]],\n\n        [[-0.7019]],\n\n        [[-0.8639]],\n\n        [[ 0.8962]],\n\n        [[-0.3282]],\n\n        [[ 0.3715]],\n\n        [[-0.7970]],\n\n        [[-0.5767]],\n\n        [[ 0.9037]],\n\n        [[-0.1962]],\n\n        [[ 0.6562]],\n\n        [[-0.9602]],\n\n        [[-0.9493]],\n\n        [[-0.8167]],\n\n        [[-0.1808]],\n\n        [[ 0.6962]],\n\n        [[-0.7077]],\n\n        [[-0.7834]],\n\n        [[-0.1172]],\n\n        [[ 0.3560]],\n\n        [[ 0.5428]],\n\n        [[-0.2490]],\n\n        [[-0.2016]],\n\n        [[ 0.5683]],\n\n        [[-0.1658]],\n\n        [[-0.8857]]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.556156Z",
     "end_time": "2023-11-20T13:22:24.617850Z"
    },
    "id": "-jQ6AtzAj_zb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) tensor([2, 3, 7, 9, 3, 9, 1, 3, 9, 3, 3, 5, 1, 9, 1, 5, 8, 1, 2, 2, 2, 8, 0, 4,\n",
      "        6, 9, 2, 5, 1, 3, 1, 4, 6, 6, 7, 0, 5, 6, 0, 6, 9, 7, 8, 5, 2, 5, 5, 7,\n",
      "        1, 6, 2, 9, 0, 5, 0, 8, 8, 7, 7, 2, 6, 5, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "i1, l1 = next(iter(mnist_dl))\n",
    "print(i1.shape, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xflMq66j_zc"
   },
   "source": [
    "## Dissimilarity measures between two distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2JQp7T2j_zc"
   },
   "source": [
    "## Gradient penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-uVyHScj_zc"
   },
   "source": [
    "## Implementing WGAN-GP to train the DCGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.587848Z",
     "end_time": "2023-11-20T13:22:24.617850Z"
    },
    "id": "hchcGDqqj_zc"
   },
   "outputs": [],
   "source": [
    "def make_generator_network_wgan(input_size, n_filters):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(input_size, n_filters*4, 4, 1, 0,\n",
    "                           bias=False),\n",
    "        nn.InstanceNorm2d(n_filters*4),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters*4, n_filters*2, 3, 2, 1, bias=False),\n",
    "        nn.InstanceNorm2d(n_filters*2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters*2, n_filters, 4, 2, 1, bias=False),\n",
    "        nn.InstanceNorm2d(n_filters),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
    "        nn.Tanh())\n",
    "    return model\n",
    "\n",
    "class DiscriminatorWGAN(nn.Module):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, n_filters, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters, n_filters*2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(n_filters * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*2, n_filters*4, 3, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(n_filters*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.608254Z",
     "end_time": "2023-11-20T13:22:24.625270Z"
    },
    "id": "YblM7h4pj_zd"
   },
   "outputs": [],
   "source": [
    "gen_model = make_generator_network_wgan(z_size, n_filters).to(device)\n",
    "disc_model = DiscriminatorWGAN(n_filters).to(device)\n",
    "\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0002)\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:24.627346Z",
     "end_time": "2023-11-20T13:22:24.693102Z"
    },
    "id": "7U4qAagvj_zd"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import grad as torch_grad\n",
    "\n",
    "\n",
    "def gradient_penalty(real_data, generated_data):\n",
    "    batch_size = real_data.size(0)\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(real_data.shape[0], 1, 1, 1, requires_grad=True, device=device)\n",
    "    interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    proba_interpolated = disc_model(interpolated)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=proba_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(proba_interpolated.size(), device=device),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradients_norm = gradients.norm(2, dim=1)\n",
    "    return lambda_gp * ((gradients_norm - 1)**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:57.727531Z",
     "end_time": "2023-11-20T13:22:57.759052Z"
    },
    "id": "Br-o3mZOj_zd"
   },
   "outputs": [],
   "source": [
    "## Train the discriminator\n",
    "def d_train_wgan(x):\n",
    "    disc_model.zero_grad()\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    x = x.to(device)\n",
    "    print(\"X\", x.shape)\n",
    "\n",
    "    # Calculate probabilities on real and generated data\n",
    "    d_real = disc_model(x)\n",
    "    print(\"D real\", d_real.mean())\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_output = gen_model(input_z)\n",
    "    print(\"G output\", g_output.shape)\n",
    "    d_generated = disc_model(g_output)\n",
    "    print(\"D generated\", d_generated.shape)\n",
    "    d_loss = d_generated.mean() - d_real.mean() + gradient_penalty(x.data, g_output.data)\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "    return d_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-20T13:22:58.042463Z",
     "end_time": "2023-11-20T13:22:58.073855Z"
    },
    "id": "fEWANti8j_zd"
   },
   "outputs": [],
   "source": [
    "## Train the generator\n",
    "def g_train_wgan(x):\n",
    "    gen_model.zero_grad()\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_output = gen_model(input_z)\n",
    "\n",
    "    d_generated = disc_model(g_output)\n",
    "    g_loss = -d_generated.mean()\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    return g_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7v2Jk1Lj_zd",
    "outputId": "4a232d63-4f17-48d7-be0b-06c662fd739e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G loss: tensor(-0.3837, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3242, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3431, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3712, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3411, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3737, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3200, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3184, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3455, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3095, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2968, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3204, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2938, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2980, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2867, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2948, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3067, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3023, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3711, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2966, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2749, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3481, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2492, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3163, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2391, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2138, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2783, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2038, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2792, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2414, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2258, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2247, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2974, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2493, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.1928, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2410, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.1730, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2799, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3256, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2603, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2441, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2025, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2227, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.1570, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3017, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.1274, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.2252, grad_fn=<NegBackward0>)\n",
      "G loss: tensor(-0.3427, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m         d_loss \u001B[38;5;241m=\u001B[39m d_train_wgan(x)\n\u001B[0;32m     13\u001B[0m     d_losses\u001B[38;5;241m.\u001B[39mappend(d_loss)\n\u001B[1;32m---> 14\u001B[0m     g_losses\u001B[38;5;241m.\u001B[39mappend(\u001B[43mg_train_wgan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | D Loss >>\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     17\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39mFloatTensor(d_losses)\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     18\u001B[0m gen_model\u001B[38;5;241m.\u001B[39meval()\n",
      "Cell \u001B[1;32mIn[21], line 14\u001B[0m, in \u001B[0;36mg_train_wgan\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mG loss:\u001B[39m\u001B[38;5;124m\"\u001B[39m, g_loss)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# gradient backprop & optimize ONLY G's parameters\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m \u001B[43mg_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m g_optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m g_loss\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epoch_samples_wgan = []\n",
    "lambda_gp = 10.0\n",
    "num_epochs = 100\n",
    "torch.manual_seed(1)\n",
    "critic_iterations = 5\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    gen_model.train()\n",
    "    d_losses, g_losses = [], []\n",
    "    for i, (x, _) in enumerate(mnist_dl):\n",
    "        for _ in range(critic_iterations):\n",
    "            d_loss = d_train_wgan(x)\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_train_wgan(x))\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | D Loss >>'\n",
    "          f' {torch.FloatTensor(d_losses).mean():.4f}')\n",
    "    gen_model.eval()\n",
    "    epoch_samples_wgan.append(\n",
    "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4g2ZJjvj_ze"
   },
   "outputs": [],
   "source": [
    "selected_epochs = [1, 2, 4, 10, 50, 100]\n",
    "# selected_epochs = [1, 10, 20, 30, 50, 70]\n",
    "fig = plt.figure(figsize=(10, 14))\n",
    "for i,e in enumerate(selected_epochs):\n",
    "    for j in range(5):\n",
    "        ax = fig.add_subplot(6, 5, i*5+j+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:\n",
    "            ax.text(\n",
    "                -0.06, 0.5, f'Epoch {e}',\n",
    "                rotation=90, size=18, color='red',\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='center',\n",
    "                transform=ax.transAxes)\n",
    "\n",
    "        image = epoch_samples_wgan[e-1][j]\n",
    "        ax.imshow(image, cmap='gray_r')\n",
    "\n",
    "# plt.savefig('figures/ch17-wgan-gp-samples.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf9ZoMCrj_ze"
   },
   "source": [
    "## Mode collapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXah9WLpj_zf"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhD085Ksj_zf"
   },
   "source": [
    "\n",
    "\n",
    "Readers may ignore the next cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGKjUXq5j_zf"
   },
   "outputs": [],
   "source": [
    "! python ../.convert_notebook_to_script.py --input ch17_part2.ipynb --output ch17_part2.py"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tciIxnE1mogX"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
