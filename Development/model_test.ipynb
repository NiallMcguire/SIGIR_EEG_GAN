{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-16T17:54:02.053015Z",
     "end_time": "2023-10-16T17:54:02.060950Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, text_embedding_size, noise_dim, eeg_channels, eeg_samples, *args, **kwargs):\n",
    "        super(*args, **kwargs).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(text_embedding_size + noise_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, eeg_channels * eeg_samples)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_embedding, noise):\n",
    "        x = torch.cat((text_embedding, noise), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x.view(x.size(0), eeg_channels, eeg_samples)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, eeg_channels, eeg_samples, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(eeg_channels, 3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=(1, 3)),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * (eeg_samples - 4), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, eeg_data):\n",
    "        x = eeg_data.unsqueeze(1)  # Add a channel dimension\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define a custom dataset class\n",
    "class EEGTextDataset(Dataset):\n",
    "    def __init__(self, eeg_data, text_embeddings):\n",
    "        self.eeg_data = eeg_data\n",
    "        self.text_embeddings = text_embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.eeg_data[idx], self.text_embeddings[idx]\n",
    "\n",
    "# Assuming you have your EEG data and text embeddings as tensors\n",
    "eeg_data = torch.randn(100, 24, 5)  # Example: 100 samples of EEG data\n",
    "text_embeddings = torch.randn(100, 300)  # Example: 100 samples of text embeddings\n",
    "\n",
    "# Create a dataset instance\n",
    "dataset = EEGTextDataset(eeg_data, text_embeddings)\n",
    "\n",
    "# Define a data loader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T17:54:02.252407Z",
     "end_time": "2023-10-16T17:54:02.261334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Loss_D: 1.4011 Loss_G: 0.7160\n",
      "Epoch [1/100] Loss_D: 1.3606 Loss_G: 0.6928\n",
      "Epoch [2/100] Loss_D: 1.2660 Loss_G: 0.6579\n",
      "Epoch [3/100] Loss_D: 1.2550 Loss_G: 0.6427\n",
      "Epoch [4/100] Loss_D: 1.2582 Loss_G: 0.6460\n",
      "Epoch [5/100] Loss_D: 1.2469 Loss_G: 0.6261\n",
      "Epoch [6/100] Loss_D: 1.1740 Loss_G: 0.6349\n",
      "Epoch [7/100] Loss_D: 1.2293 Loss_G: 0.6506\n",
      "Epoch [8/100] Loss_D: 1.1482 Loss_G: 0.6851\n",
      "Epoch [9/100] Loss_D: 1.1263 Loss_G: 0.6758\n",
      "Epoch [10/100] Loss_D: 1.0750 Loss_G: 0.7445\n",
      "Epoch [11/100] Loss_D: 1.0365 Loss_G: 0.7611\n",
      "Epoch [12/100] Loss_D: 1.0769 Loss_G: 0.7677\n",
      "Epoch [13/100] Loss_D: 0.9156 Loss_G: 0.7897\n",
      "Epoch [14/100] Loss_D: 1.0535 Loss_G: 0.7400\n",
      "Epoch [15/100] Loss_D: 1.0241 Loss_G: 0.7966\n",
      "Epoch [16/100] Loss_D: 0.8636 Loss_G: 0.8825\n",
      "Epoch [17/100] Loss_D: 1.0826 Loss_G: 0.6838\n",
      "Epoch [18/100] Loss_D: 0.8491 Loss_G: 0.8497\n",
      "Epoch [19/100] Loss_D: 1.0642 Loss_G: 0.8057\n",
      "Epoch [20/100] Loss_D: 1.0452 Loss_G: 0.6950\n",
      "Epoch [21/100] Loss_D: 1.1174 Loss_G: 0.7816\n",
      "Epoch [22/100] Loss_D: 0.8340 Loss_G: 0.9203\n",
      "Epoch [23/100] Loss_D: 1.0175 Loss_G: 0.9457\n",
      "Epoch [24/100] Loss_D: 0.8058 Loss_G: 0.9586\n",
      "Epoch [25/100] Loss_D: 0.8778 Loss_G: 0.8155\n",
      "Epoch [26/100] Loss_D: 0.8234 Loss_G: 0.9703\n",
      "Epoch [27/100] Loss_D: 0.7677 Loss_G: 0.9168\n",
      "Epoch [28/100] Loss_D: 1.0964 Loss_G: 0.7787\n",
      "Epoch [29/100] Loss_D: 0.6874 Loss_G: 1.0258\n",
      "Epoch [30/100] Loss_D: 0.9502 Loss_G: 0.9008\n",
      "Epoch [31/100] Loss_D: 0.8075 Loss_G: 1.2720\n",
      "Epoch [32/100] Loss_D: 0.7929 Loss_G: 1.1896\n",
      "Epoch [33/100] Loss_D: 1.1409 Loss_G: 1.2418\n",
      "Epoch [34/100] Loss_D: 0.5949 Loss_G: 1.3193\n",
      "Epoch [35/100] Loss_D: 0.9917 Loss_G: 1.2188\n",
      "Epoch [36/100] Loss_D: 0.9626 Loss_G: 1.0024\n",
      "Epoch [37/100] Loss_D: 1.3678 Loss_G: 0.6838\n",
      "Epoch [38/100] Loss_D: 1.1749 Loss_G: 1.1709\n",
      "Epoch [39/100] Loss_D: 1.6245 Loss_G: 0.9168\n",
      "Epoch [40/100] Loss_D: 0.9353 Loss_G: 1.1619\n",
      "Epoch [41/100] Loss_D: 1.1608 Loss_G: 0.8731\n",
      "Epoch [42/100] Loss_D: 1.0820 Loss_G: 1.3194\n",
      "Epoch [43/100] Loss_D: 1.2498 Loss_G: 0.9840\n",
      "Epoch [44/100] Loss_D: 0.9380 Loss_G: 1.2312\n",
      "Epoch [45/100] Loss_D: 1.2844 Loss_G: 1.1729\n",
      "Epoch [46/100] Loss_D: 0.9442 Loss_G: 1.1985\n",
      "Epoch [47/100] Loss_D: 0.7382 Loss_G: 1.2371\n",
      "Epoch [48/100] Loss_D: 0.9844 Loss_G: 1.1180\n",
      "Epoch [49/100] Loss_D: 0.7881 Loss_G: 1.2305\n",
      "Epoch [50/100] Loss_D: 0.4460 Loss_G: 1.6762\n",
      "Epoch [51/100] Loss_D: 1.0280 Loss_G: 1.2612\n",
      "Epoch [52/100] Loss_D: 0.8184 Loss_G: 1.0127\n",
      "Epoch [53/100] Loss_D: 0.9602 Loss_G: 1.4634\n",
      "Epoch [54/100] Loss_D: 0.7987 Loss_G: 1.2048\n",
      "Epoch [55/100] Loss_D: 0.5349 Loss_G: 1.9895\n",
      "Epoch [56/100] Loss_D: 0.6317 Loss_G: 1.9004\n",
      "Epoch [57/100] Loss_D: 0.6077 Loss_G: 1.2461\n",
      "Epoch [58/100] Loss_D: 0.6749 Loss_G: 1.4215\n",
      "Epoch [59/100] Loss_D: 0.4146 Loss_G: 1.7906\n",
      "Epoch [60/100] Loss_D: 0.8240 Loss_G: 1.6853\n",
      "Epoch [61/100] Loss_D: 0.8579 Loss_G: 1.5344\n",
      "Epoch [62/100] Loss_D: 0.7089 Loss_G: 1.7184\n",
      "Epoch [63/100] Loss_D: 0.6593 Loss_G: 1.4635\n",
      "Epoch [64/100] Loss_D: 1.2010 Loss_G: 1.6377\n",
      "Epoch [65/100] Loss_D: 1.1854 Loss_G: 1.4998\n",
      "Epoch [66/100] Loss_D: 0.6653 Loss_G: 2.0286\n",
      "Epoch [67/100] Loss_D: 0.3320 Loss_G: 2.1398\n",
      "Epoch [68/100] Loss_D: 0.6164 Loss_G: 1.5170\n",
      "Epoch [69/100] Loss_D: 1.2169 Loss_G: 1.9113\n",
      "Epoch [70/100] Loss_D: 0.6267 Loss_G: 1.7878\n",
      "Epoch [71/100] Loss_D: 0.5647 Loss_G: 2.0893\n",
      "Epoch [72/100] Loss_D: 0.4494 Loss_G: 1.8554\n",
      "Epoch [73/100] Loss_D: 1.0623 Loss_G: 1.4407\n",
      "Epoch [74/100] Loss_D: 0.6775 Loss_G: 1.4459\n",
      "Epoch [75/100] Loss_D: 0.8512 Loss_G: 1.1502\n",
      "Epoch [76/100] Loss_D: 0.7688 Loss_G: 1.2984\n",
      "Epoch [77/100] Loss_D: 0.3995 Loss_G: 1.5023\n",
      "Epoch [78/100] Loss_D: 0.4394 Loss_G: 1.7018\n",
      "Epoch [79/100] Loss_D: 0.6222 Loss_G: 1.5061\n",
      "Epoch [80/100] Loss_D: 0.8166 Loss_G: 1.4886\n",
      "Epoch [81/100] Loss_D: 1.0340 Loss_G: 2.0464\n",
      "Epoch [82/100] Loss_D: 0.6018 Loss_G: 1.4597\n",
      "Epoch [83/100] Loss_D: 1.0196 Loss_G: 1.2158\n",
      "Epoch [84/100] Loss_D: 0.7646 Loss_G: 1.6813\n",
      "Epoch [85/100] Loss_D: 0.6021 Loss_G: 2.3552\n",
      "Epoch [86/100] Loss_D: 0.8073 Loss_G: 1.8621\n",
      "Epoch [87/100] Loss_D: 0.6981 Loss_G: 1.4347\n",
      "Epoch [88/100] Loss_D: 0.9606 Loss_G: 1.2938\n",
      "Epoch [89/100] Loss_D: 0.8556 Loss_G: 1.4497\n",
      "Epoch [90/100] Loss_D: 0.7961 Loss_G: 1.2822\n",
      "Epoch [91/100] Loss_D: 0.7622 Loss_G: 1.8670\n",
      "Epoch [92/100] Loss_D: 0.3110 Loss_G: 2.3225\n",
      "Epoch [93/100] Loss_D: 0.2469 Loss_G: 2.8140\n",
      "Epoch [94/100] Loss_D: 0.8620 Loss_G: 1.6708\n",
      "Epoch [95/100] Loss_D: 0.5082 Loss_G: 1.4740\n",
      "Epoch [96/100] Loss_D: 0.3018 Loss_G: 2.2192\n",
      "Epoch [97/100] Loss_D: 0.5723 Loss_G: 1.9228\n",
      "Epoch [98/100] Loss_D: 0.6726 Loss_G: 2.4778\n",
      "Epoch [99/100] Loss_D: 0.5108 Loss_G: 2.1039\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the GAN\n",
    "text_embedding_size = 300  # Adjust based on your text embeddings\n",
    "noise_dim = 100\n",
    "eeg_channels = 24\n",
    "eeg_samples = 5\n",
    "\n",
    "generator = Generator(text_embedding_size, noise_dim, eeg_channels, eeg_samples)\n",
    "discriminator = Discriminator(eeg_channels, eeg_samples)\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Training loop (you'll need to have a dataset of real EEG data and text embeddings)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for real_eeg_data, text_embedding in dataloader:  # You need to define a dataloader for your dataset\n",
    "        real_labels = torch.ones((real_eeg_data.size(0), 1))\n",
    "        fake_labels = torch.zeros((real_eeg_data.size(0), 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_outputs = discriminator(real_eeg_data)\n",
    "        fake_eeg_data = generator(text_embedding, torch.randn(real_eeg_data.size(0), noise_dim))\n",
    "        fake_outputs = discriminator(fake_eeg_data.detach())\n",
    "        loss_real = criterion(real_outputs, real_labels)\n",
    "        loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train the generator\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_outputs = discriminator(fake_eeg_data)\n",
    "        loss_G = criterion(fake_outputs, real_labels)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch}/{num_epochs}] Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T17:54:02.486519Z",
     "end_time": "2023-10-16T17:54:06.928198Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T17:55:40.553136Z",
     "end_time": "2023-10-16T17:55:40.564047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\AppData\\Local\\Temp\\ipykernel_11628\\2108227243.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings, dtype=torch.float32)\n",
      "C:\\Users\\niall\\AppData\\Local\\Temp\\ipykernel_11628\\2108227243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  noise = torch.tensor(noise, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 2.0080e-01, -2.7315e-01, -1.3623e+00,  1.3018e+00,  9.4885e-01],\n        [-1.0215e+00, -3.0463e-01, -4.7836e-01,  2.1656e-01,  2.4706e-01],\n        [ 7.9356e-01, -1.0140e-01,  2.4798e-01, -1.1678e+00, -1.1323e+00],\n        [-6.4252e-01, -9.9927e-01, -9.1466e-01, -9.3116e-01, -1.2791e+00],\n        [-1.1923e+00, -7.5123e-02,  5.1690e-01,  6.5738e-01,  8.2234e-01],\n        [-6.1131e-01,  3.9240e-01, -1.1282e+00, -3.7267e-01, -8.0096e-01],\n        [-2.4545e-01,  3.9074e-01, -4.7375e-01,  6.1411e-01,  1.3573e+00],\n        [-4.4284e-01,  1.0560e+00,  6.4665e-01, -2.6015e-01, -3.8711e-01],\n        [ 7.5872e-01, -6.0898e-01,  7.0539e-02, -1.3710e+00, -7.5046e-01],\n        [-1.1724e+00,  1.1318e+00, -1.1710e+00,  3.1407e-01,  8.4863e-01],\n        [ 1.5855e-01,  5.6216e-01,  6.3915e-01,  8.2472e-01, -4.4520e-01],\n        [-5.3836e-01,  4.7662e-01, -8.2559e-01,  3.6270e-01, -1.4792e-01],\n        [-5.4914e-01,  4.9456e-01, -5.9625e-01,  2.7490e-02,  2.9979e-01],\n        [-6.0342e-01, -9.3386e-01, -8.2052e-01,  7.8115e-01,  1.0588e+00],\n        [-1.2325e+00, -1.5083e-01,  4.8526e-01,  3.9740e-01, -7.4385e-01],\n        [-8.3920e-01, -2.6515e-01,  3.8596e-01, -8.6689e-03,  5.9015e-01],\n        [-9.8684e-02,  4.9716e-01,  1.6939e-01,  7.5238e-01,  1.0386e+00],\n        [-2.8205e-01,  8.2743e-01, -7.6519e-01, -1.0911e+00,  4.1299e-01],\n        [-1.5239e+00, -7.1031e-01, -9.4386e-01, -4.6193e-01,  3.7154e-01],\n        [ 1.0197e+00,  1.5263e-03,  2.2745e-01,  6.2919e-01,  5.0743e-01],\n        [ 2.6214e-01,  6.6178e-01,  1.2112e-01, -5.9842e-01, -1.1415e+00],\n        [-6.5280e-01,  8.7616e-01, -9.9340e-01,  1.0876e+00,  1.0487e+00],\n        [-4.3512e-01, -8.0100e-01,  7.8758e-01, -5.8950e-02,  1.4651e+00],\n        [ 2.2619e-01,  4.8753e-02, -1.5384e+00, -2.0759e-01,  2.2582e-02]],\n       grad_fn=<ViewBackward0>)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.eval()  # Set the generator in evaluation mode\n",
    "\n",
    "# 1. Generate text embeddings for the desired text\n",
    "text_embeddings = torch.randn(1, 300)\n",
    "text_embeddings = torch.tensor(text_embeddings, dtype=torch.float32)\n",
    "\n",
    "# 2. Generate random noise\n",
    "noise = torch.randn(1, noise_dim)  # Use a batch size of 1 for a single example\n",
    "noise = torch.tensor(noise, dtype=torch.float32)\n",
    "\n",
    "# 3. Use the generator\n",
    "synthetic_eeg_data = generator(text_embeddings, noise)\n",
    "\n",
    "# 4. Reshape and format the synthetic data\n",
    "synthetic_eeg_data = synthetic_eeg_data.view(24, 5)  # Reshape to match the real EEG data shape\n",
    "\n",
    "# Now, synthetic_eeg_data contains the generated EEG data in the desired format\n",
    "\n",
    "synthetic_eeg_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:01:49.647978Z",
     "end_time": "2023-10-16T18:01:49.657898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:01:37.029741Z",
     "end_time": "2023-10-16T18:01:37.037677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:01:37.295597Z",
     "end_time": "2023-10-16T18:01:37.304029Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:01:40.407004Z",
     "end_time": "2023-10-16T18:01:40.414444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
