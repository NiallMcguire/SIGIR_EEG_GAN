{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:24:30.617244Z",
     "end_time": "2023-11-08T13:24:30.630670Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:24:32.346422Z",
     "end_time": "2023-11-08T13:24:35.393028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:24:38.288000Z",
     "end_time": "2023-11-08T13:24:38.833567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:25:08.442301Z",
     "end_time": "2023-11-08T13:25:08.459232Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# To load the lists from the file:\n",
    "with open(r'C:\\Users\\gxb18167\\PycharmProjects\\SIGIR_EEG_GAN\\Development\\EEG-To-Text-GAN\\Data\\EEG_Text_Pairs.pkl', 'rb') as file:\n",
    "    EEG_word_level_embeddings = pickle.load(file)\n",
    "    EEG_word_level_labels = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:25:41.432643Z",
     "end_time": "2023-11-08T13:25:41.893678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gxb18167\\AppData\\Local\\Temp\\ipykernel_24712\\839738786.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_abjetg6_iu\\croot\\pytorch_1686932924616\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  float_tensor = torch.tensor(EEG_word_level_embeddings, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "float_tensor = torch.tensor(EEG_word_level_embeddings, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:38:03.809695Z",
     "end_time": "2023-11-08T13:38:03.826726Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([105, 8])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:42:53.068973Z",
     "end_time": "2023-11-08T13:42:53.092507Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import torch\n",
    "train_data = []\n",
    "for i in range(len(float_tensor)):\n",
    "   train_data.append([float_tensor[i], EEG_word_level_labels[i]])\n",
    "\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:38:28.800004Z",
     "end_time": "2023-11-08T13:38:29.078097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T13:38:29.913447Z",
     "end_time": "2023-11-08T13:38:29.925446Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.7698, 1.3693, 1.0006, 1.0377, 0.9263, 0.3586, 1.3011, 0.9097],\n",
      "         [1.0833, 1.1161, 0.5786, 1.0576, 1.1416, 1.1544, 0.9489, 0.6407],\n",
      "         [0.7564, 1.1634, 0.8472, 1.7551, 0.6858, 0.9577, 0.7568, 0.5076],\n",
      "         [0.4106, 1.1224, 1.7265, 0.8217, 0.8020, 0.8461, 3.0502, 0.9161],\n",
      "         [1.8313, 1.2387, 1.2132, 1.0831, 0.5694, 2.3264, 1.7901, 1.7870],\n",
      "         [3.2848, 3.0052, 2.5046, 1.6938, 1.1088, 0.4108, 3.6942, 3.6750],\n",
      "         [3.3399, 2.9089, 2.1167, 2.4074, 3.8752, 4.0677, 4.0108, 3.5303],\n",
      "         [4.3200, 3.7503, 3.9125, 3.3102, 3.6240, 3.6315, 3.5991, 2.3649],\n",
      "         [1.7955, 0.7117, 1.1090, 3.6161, 4.7058, 2.7662, 2.2068, 1.6651],\n",
      "         [1.0571, 3.3795, 3.1622, 2.6551, 1.8112, 1.4100, 3.1329, 2.6095],\n",
      "         [2.3858, 1.6953, 2.7671, 3.1854, 1.7641, 1.1121, 1.0452, 1.3722],\n",
      "         [0.7494, 2.2713, 0.9478, 0.7662, 1.3037, 1.0658, 1.5393, 2.0574],\n",
      "         [1.2024, 1.0218, 1.5682, 1.1326, 1.6254, 2.1454, 2.3601, 1.6923],\n",
      "         [0.0000, 1.4240, 0.2987, 0.2383, 0.3204, 0.2926, 0.3060, 0.3005],\n",
      "         [0.1918, 0.3939, 0.4455, 0.3276, 0.3195, 0.3980, 0.4271, 0.4537],\n",
      "         [0.5019, 0.3467, 0.4857, 0.5874, 0.5397, 0.8273, 0.5794, 0.5347],\n",
      "         [0.4307, 0.3155, 0.7278, 0.7851, 0.7301, 0.6870, 0.5570, 2.1384],\n",
      "         [1.3458, 0.7247, 0.7971, 0.8292, 1.3882, 1.0552, 0.9362, 0.8574],\n",
      "         [0.8540, 1.2773, 1.0181, 0.9086, 0.7869, 0.5486, 0.2942, 2.2024],\n",
      "         [1.0386, 1.1230, 1.1445, 0.8685, 0.9827, 1.9493, 1.2508, 1.2175],\n",
      "         [1.4103, 2.7014, 1.9637, 1.6537, 1.3095, 2.4606, 2.0572, 1.3954],\n",
      "         [1.1701, 0.7060, 0.6018, 0.7404, 1.9870, 1.5605, 1.1535, 0.7436],\n",
      "         [0.5399, 0.6388, 1.5979, 0.9421, 1.0216, 0.5868, 0.4758, 0.5277],\n",
      "         [0.5684, 0.6140, 0.7034, 0.7654, 1.1160, 0.7089, 0.6588, 0.4532],\n",
      "         [0.3907, 0.1373, 0.7481, 0.7599, 0.4720, 0.3927, 0.1411, 0.8511],\n",
      "         [1.0597, 0.4734, 0.3736, 0.2480, 0.5769, 0.6459, 0.5815, 0.4520],\n",
      "         [0.2102, 0.0000, 0.7257, 0.5014, 0.6548, 0.8973, 0.9305, 0.2318],\n",
      "         [0.5866, 0.6382, 0.9753, 0.9976, 0.1654, 0.8895, 0.9664, 0.9823],\n",
      "         [0.9473, 0.4671, 0.8718, 0.9247, 0.6199, 1.0071, 0.7312, 0.5932],\n",
      "         [0.5049, 0.2122, 0.5078, 0.5119, 1.0582, 0.8379, 0.7502, 0.9688],\n",
      "         [0.6745, 0.8655, 1.3389, 1.3159, 1.3777, 0.8558, 0.6459, 1.4689],\n",
      "         [1.4583, 1.4718, 1.7684, 1.8077, 1.7944, 1.8090, 1.4531, 0.7760],\n",
      "         [1.7374, 2.2613, 2.4461, 2.5894, 2.3334, 2.7716, 1.9715, 2.3664],\n",
      "         [2.6169, 3.1396, 1.6051, 2.0938, 3.3144, 3.2202, 1.3409, 2.7041],\n",
      "         [3.4099, 3.1028, 2.0191, 0.9724, 0.2934, 1.4437, 3.1176, 3.0846],\n",
      "         [2.4080, 1.5565, 0.6608, 1.1295, 2.8655, 2.6333, 1.7369, 1.1016],\n",
      "         [1.4932, 2.1827, 1.6075, 1.2800, 1.3147, 1.2088, 1.0719, 0.9247],\n",
      "         [0.4739, 0.2702, 0.5126, 1.0317, 0.7243, 0.4906, 0.3000, 0.5535],\n",
      "         [0.9045, 0.7824, 0.4857, 0.4977, 0.5344, 0.7540, 1.0941, 0.8250],\n",
      "         [0.7139, 0.5589, 0.0000, 0.8279, 0.5522, 0.6343, 0.9576, 0.8034],\n",
      "         [0.4213, 0.8905, 0.6363, 0.8623, 0.9689, 0.4558, 0.9079, 0.7995],\n",
      "         [0.8643, 0.8292, 0.5730, 0.7122, 0.9306, 0.6043, 1.3190, 0.7866],\n",
      "         [0.7879, 0.6134, 0.5129, 0.4080, 0.6997, 1.0004, 0.7462, 0.7331],\n",
      "         [0.6960, 1.6468, 0.7420, 0.9302, 0.9146, 0.9383, 0.4409, 0.2682],\n",
      "         [0.8254, 0.8819, 0.9404, 0.8961, 1.0529, 1.1191, 1.1366, 0.8720],\n",
      "         [0.5494, 0.8028, 1.3232, 1.5458, 1.6714, 1.3474, 1.5721, 1.0024],\n",
      "         [1.4688, 1.5636, 1.8139, 1.1529, 1.4766, 1.9411, 1.9193, 1.1927],\n",
      "         [1.9250, 2.0937, 1.9201, 1.2831, 0.8897, 0.6023, 1.5544, 2.5969],\n",
      "         [2.2463, 1.6611, 1.2321, 0.7418, 1.6504, 2.5395, 1.8742, 1.4582],\n",
      "         [1.1774, 1.7940, 1.8221, 1.4953, 1.3478, 1.3564, 1.1983, 1.1833],\n",
      "         [1.3719, 0.8995, 0.7145, 0.6282, 0.9835, 1.2748, 0.7998, 0.7714],\n",
      "         [0.7630, 0.8036, 0.7700, 0.8034, 0.5171, 0.8603, 0.6236, 0.7956],\n",
      "         [0.7181, 1.1409, 0.9454, 0.0000, 0.7542, 0.4578, 0.4758, 0.3431],\n",
      "         [0.2594, 0.3668, 0.5930, 0.5131, 0.3980, 0.3827, 0.4827, 0.4728],\n",
      "         [0.4175, 0.4737, 0.4674, 0.5170, 0.8733, 0.5992, 0.5271, 0.9133],\n",
      "         [0.8124, 0.7478, 0.5831, 0.5567, 0.4543, 0.9646, 1.2312, 0.9359],\n",
      "         [0.8965, 0.7732, 1.9672, 0.9241, 1.1604, 1.0771, 1.0053, 0.5281],\n",
      "         [0.7665, 1.6487, 1.1949, 1.1746, 1.2541, 1.1875, 1.1898, 1.0656],\n",
      "         [0.8995, 0.5821, 1.4192, 1.4486, 1.3697, 1.2563, 1.3655, 1.8708],\n",
      "         [1.6624, 1.6223, 1.6397, 2.1450, 1.9803, 2.1892, 2.4592, 2.4796],\n",
      "         [2.0530, 2.7844, 2.6932, 2.2471, 1.3648, 0.8586, 0.6463, 2.3800],\n",
      "         [3.4745, 2.4988, 1.7625, 1.1764, 0.6952, 2.0252, 2.7319, 2.0139],\n",
      "         [1.3432, 1.0106, 1.8655, 1.9854, 1.3216, 1.1268, 1.2296, 1.3730],\n",
      "         [0.9478, 1.2050, 0.7316, 0.5587, 0.4161, 0.7589, 1.6862, 0.9045],\n",
      "         [0.5765, 0.3684, 0.7743, 0.6217, 0.8837, 0.3784, 0.5549, 0.6954],\n",
      "         [0.8449, 0.8676, 1.1686, 0.7408, 0.0000, 1.2593, 0.5716, 0.5344],\n",
      "         [0.6961, 0.7160, 0.4283, 0.6514, 0.5928, 0.6515, 0.7489, 0.4771],\n",
      "         [0.5170, 0.6143, 0.5871, 0.6218, 0.6547, 0.8034, 0.7595, 0.7731],\n",
      "         [0.9277, 1.0892, 0.7668, 0.7240, 0.4796, 0.3112, 0.8623, 1.1161],\n",
      "         [0.8740, 0.7941, 0.5513, 1.2085, 1.0072, 1.2703, 1.0040, 1.0086],\n",
      "         [0.8225, 0.6989, 1.4447, 1.1113, 1.0650, 1.1032, 0.9285, 0.8532],\n",
      "         [0.8007, 0.5526, 0.3279, 1.2023, 1.4166, 1.3455, 1.3014, 0.8329],\n",
      "         [0.9156, 1.7667, 1.6012, 1.3500, 1.1390, 1.9244, 1.5955, 1.1199],\n",
      "         [1.2444, 1.7442, 1.5637, 1.2975, 0.9671, 0.7583, 0.6866, 0.3633],\n",
      "         [1.4989, 1.7295, 1.0798, 0.8365, 0.6811, 0.5339, 1.1201, 1.0774],\n",
      "         [0.9726, 0.7434, 0.6729, 1.0921, 1.1542, 0.9206, 0.8184, 1.2731],\n",
      "         [1.5363, 0.7800, 0.7021, 0.5164, 0.4456, 0.6159, 1.0845, 1.2239],\n",
      "         [0.8172, 0.4368, 0.5193, 0.8895, 0.7299, 0.5863, 0.4475, 0.6148],\n",
      "         [0.8966, 0.9462, 0.6687, 0.9836, 0.7049, 0.0000, 0.7341, 0.6213],\n",
      "         [0.8286, 1.0222, 0.8861, 0.4253, 0.7816, 0.8548, 0.9476, 0.9840],\n",
      "         [0.5997, 0.9422, 0.9252, 0.9600, 0.9041, 0.7828, 0.9839, 1.0274],\n",
      "         [0.8809, 1.7832, 1.1737, 1.0430, 0.8991, 0.6035, 0.3436, 0.6886],\n",
      "         [1.1923, 0.8987, 0.8217, 0.6548, 1.4248, 1.1035, 1.5675, 1.1948],\n",
      "         [1.1991, 1.1439, 0.6402, 1.7523, 1.2484, 1.2218, 1.3235, 1.2435],\n",
      "         [1.2160, 0.8808, 0.5797, 0.3050, 1.1460, 1.2952, 1.2095, 1.2399],\n",
      "         [0.8456, 0.9290, 1.5078, 1.3651, 1.2767, 1.2770, 1.7254, 1.5410],\n",
      "         [1.3929, 1.2678, 1.5420, 1.5993, 1.2800, 1.0397, 0.6860, 0.5933],\n",
      "         [0.3779, 1.5349, 1.4175, 1.0647, 0.9412, 0.7249, 0.4714, 1.2363],\n",
      "         [1.1024, 1.0765, 0.8585, 0.7693, 0.8600, 1.0348, 1.1770, 0.9051],\n",
      "         [1.6310, 2.0254, 0.9247, 1.0162, 0.7161, 0.4345, 0.7817, 1.0104],\n",
      "         [1.2243, 1.1694, 0.5739, 0.7815, 0.9336, 0.9226, 0.8100, 0.6898],\n",
      "         [0.8506, 0.7027, 0.5311, 1.0043, 1.3844, 0.9018, 0.0000, 0.9674],\n",
      "         [0.4849, 0.5214, 0.6773, 0.7453, 0.5972, 0.6033, 0.4480, 0.7153],\n",
      "         [0.7636, 0.4979, 0.7707, 0.6692, 0.6609, 0.6840, 0.6751, 0.7380],\n",
      "         [0.7073, 0.7948, 1.3488, 1.2068, 0.8168, 0.7454, 0.4436, 0.3085],\n",
      "         [0.5760, 0.9871, 0.6005, 0.5468, 0.4713, 1.3030, 1.0426, 1.2135],\n",
      "         [0.8899, 0.9961, 0.8716, 0.5911, 1.4379, 0.8456, 0.8294, 1.3742],\n",
      "         [1.1665, 1.0314, 0.6051, 0.4611, 0.4537, 1.4778, 0.8740, 0.7818],\n",
      "         [0.8209, 0.5912, 0.7356, 0.9191, 1.0132, 1.0027, 1.0478, 1.1859],\n",
      "         [1.3762, 1.2451, 1.0751, 1.2884, 1.5853, 1.2240, 0.9429, 0.8264],\n",
      "         [0.8667, 0.7520, 1.4037, 1.4674, 1.1648, 0.9909, 0.6801, 0.6539],\n",
      "         [1.2281, 1.3346, 1.3817, 0.8665, 0.7236, 1.1458, 1.1891, 1.0949],\n",
      "         [0.8303, 2.0112, 1.9488, 0.7809, 0.8206, 0.5866, 0.7531, 0.7436],\n",
      "         [0.9514, 1.1125, 0.9271, 0.6185, 0.5616, 0.9092, 0.9436, 0.6069],\n",
      "         [0.5264, 0.7875, 0.6331, 0.5391, 0.9593, 1.1716, 0.7392, 0.0000]]]) ('Julia', 'restoration', 'led', 'apprentice', 'first', 'convictions', 'Bush', 'police', 'was', 'eventually', 'later', 'Struensee', 'led', 'President', 'schooling', 'Peyton', 'W.', 'Erdoğan', 'still', 'and', 'offence', 'Besides', 'company', 'Ireland.', 'film', '2,', 'New', 'wire', 'Marge)', 'played', 'where', 'with', 'played', 'Justice', 'Gérard,', 'and', 'of', 'was', 'vengeful', 'NFL', 'loved', 'columnist', 'Franklin', 'President', 'politics', 'later', \"Barrymore's\", '1891,', 'smoking', 'of', 'developed', 'gift', 'National', 'of', 'African-American', 'disclose', 'of', 'The', 'apprenticeship', 'from', 'book,', 'movement', 'the', 'local')\n"
     ]
    }
   ],
   "source": [
    "#sanity check:\n",
    "i1, l1 = next(iter(trainloader))\n",
    "print(i1.shape, l1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:03:41.209518Z",
     "end_time": "2023-11-08T14:03:41.242506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "z_size = 100\n",
    "image_size = (105, 8)\n",
    "n_filters = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:28.387033Z",
     "end_time": "2023-11-08T14:02:28.399032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "## Loss function and optimizers:\n",
    "loss_fn = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:28.671706Z",
     "end_time": "2023-11-08T14:02:28.697394Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size, 1, 1)*2 - 1\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size, 1, 1)\n",
    "    return input_z\n",
    "\n",
    "mode_z = 'uniform'\n",
    "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "\n",
    "def create_samples(g_model, input_z):\n",
    "    g_output = g_model(input_z)\n",
    "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
    "    return (images+1)/2.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:28.876667Z",
     "end_time": "2023-11-08T14:02:28.897430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "noise = create_noise(64, 100, \"uniform\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:29.048332Z",
     "end_time": "2023-11-08T14:02:29.064336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 100, 1, 1])"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:29.245679Z",
     "end_time": "2023-11-08T14:02:29.283371Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "def make_generator_network_wgan(input_size, n_filters):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(input_size, n_filters*4, 4, 1, 0,\n",
    "                           bias=False),\n",
    "        nn.InstanceNorm2d(n_filters*4),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters*4, n_filters*2, 3, 2, 1, bias=False),\n",
    "        nn.InstanceNorm2d(n_filters*2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters*2, n_filters, 4, 2, 1, bias=False),\n",
    "        nn.InstanceNorm2d(n_filters),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
    "        nn.Tanh())\n",
    "    return model\n",
    "\n",
    "class DiscriminatorWGAN(nn.Module):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, n_filters, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters, n_filters*2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(n_filters * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*2, n_filters*4, 3, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(n_filters*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:29.449083Z",
     "end_time": "2023-11-08T14:02:29.457082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "gen_model = make_generator_network_wgan(z_size, n_filters).to(device)\n",
    "disc_model = DiscriminatorWGAN(n_filters).to(device)\n",
    "\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0002)\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:29.632731Z",
     "end_time": "2023-11-08T14:02:29.649127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "from torch.autograd import grad as torch_grad\n",
    "\n",
    "\n",
    "def gradient_penalty(real_data, generated_data):\n",
    "    batch_size = real_data.size(0)\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(real_data.shape[0], 1, 1, 1, requires_grad=True, device=device)\n",
    "    interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    proba_interpolated = disc_model(interpolated)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=proba_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(proba_interpolated.size(), device=device),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradients_norm = gradients.norm(2, dim=1)\n",
    "    return lambda_gp * ((gradients_norm - 1)**2).mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:29.824091Z",
     "end_time": "2023-11-08T14:02:29.843546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "## Train the discriminator\n",
    "def d_train_wgan(x):\n",
    "    disc_model.zero_grad()\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Calculate probabilities on real and generated data\n",
    "    d_real = disc_model(x)\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_output = gen_model(input_z)\n",
    "    d_generated = disc_model(g_output)\n",
    "    d_loss = d_generated.mean() - d_real.mean() + gradient_penalty(x.data, g_output.data)\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "    return d_loss.data.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:30.028351Z",
     "end_time": "2023-11-08T14:02:30.036364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "## Train the generator\n",
    "def g_train_wgan(x):\n",
    "    gen_model.zero_grad()\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_output = gen_model(input_z)\n",
    "\n",
    "    d_generated = disc_model(g_output)\n",
    "    g_loss = -d_generated.mean()\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    return g_loss.data.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:02:30.312564Z",
     "end_time": "2023-11-08T14:02:30.327178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (13 x 1). Kernel size: (4 x 4). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[162], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (x, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trainloader):\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(critic_iterations):\n\u001B[1;32m---> 12\u001B[0m         d_loss \u001B[38;5;241m=\u001B[39m \u001B[43md_train_wgan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     d_losses\u001B[38;5;241m.\u001B[39mappend(d_loss)\n\u001B[0;32m     14\u001B[0m     g_losses\u001B[38;5;241m.\u001B[39mappend(g_train_wgan(x))\n",
      "Cell \u001B[1;32mIn[160], line 9\u001B[0m, in \u001B[0;36md_train_wgan\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      6\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Calculate probabilities on real and generated data\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m d_real \u001B[38;5;241m=\u001B[39m \u001B[43mdisc_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m input_z \u001B[38;5;241m=\u001B[39m create_noise(batch_size, z_size, mode_z)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     11\u001B[0m g_output \u001B[38;5;241m=\u001B[39m gen_model(input_z)\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[157], line 39\u001B[0m, in \u001B[0;36mDiscriminatorWGAN.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m---> 39\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Calculated padded input size per channel: (13 x 1). Kernel size: (4 x 4). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "epoch_samples_wgan = []\n",
    "lambda_gp = 10.0\n",
    "num_epochs = 100\n",
    "torch.manual_seed(1)\n",
    "critic_iterations = 5\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    gen_model.train()\n",
    "    d_losses, g_losses = [], []\n",
    "    for i, (x, _) in enumerate(trainloader):\n",
    "        for _ in range(critic_iterations):\n",
    "            d_loss = d_train_wgan(x)\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_train_wgan(x))\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | D Loss >>'\n",
    "          f' {torch.FloatTensor(d_losses).mean():.4f}')\n",
    "    gen_model.eval()\n",
    "    epoch_samples_wgan.append(\n",
    "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
