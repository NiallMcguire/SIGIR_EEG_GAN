{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:05.205664Z",
     "end_time": "2024-03-13T15:59:05.237606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gxb18167\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "sys.path.insert(0, '..')\n",
    "import pickle\n",
    "from torch.autograd import grad as torch_grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:05.222584Z",
     "end_time": "2024-03-13T15:59:05.284553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "word_embedding_dim = 50\n",
    "output_shape = (1, 105, 8)\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:05.411708Z",
     "end_time": "2024-03-13T15:59:05.443257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "# To load the lists from the file:\n",
    "with open(r\"C:\\Users\\gxb18167\\PycharmProjects\\EEG-To-Text\\SIGIR_Development\\EEG-GAN\\EEG_Text_Pairs.pkl\", 'rb') as file:\n",
    "    EEG_word_level_embeddings = pickle.load(file)\n",
    "    EEG_word_level_labels = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:05.542245Z",
     "end_time": "2024-03-13T15:59:10.105920Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:10.115442Z",
     "end_time": "2024-03-13T15:59:10.126763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def create_word_label_embeddings(Word_Labels_List):\n",
    "    tokenized_words = []\n",
    "    for i in range(len(Word_Labels_List)):\n",
    "        tokenized_words.append([Word_Labels_List[i]])\n",
    "    model = Word2Vec(sentences=tokenized_words, vector_size=word_embedding_dim, window=5, min_count=1, workers=4)\n",
    "    word_embeddings = {word: model.wv[word] for word in model.wv.index_to_key}\n",
    "    print(\"Number of word embeddings:\", len(word_embeddings))\n",
    "    #word, embedding = list(word_embeddings.items())[10]\n",
    "    #print(f\"Word: {word}, Embedding: {embedding}\")\n",
    "\n",
    "    Embedded_Word_labels = []\n",
    "    for word in EEG_word_level_labels:\n",
    "        Embedded_Word_labels.append(word_embeddings[word])\n",
    "\n",
    "    return Embedded_Word_labels, word_embeddings\n",
    "\n",
    "def create_dataloader(EEG_word_level_embeddings, Embedded_Word_labels):\n",
    "\n",
    "\n",
    "\n",
    "    EEG_word_level_embeddings_normalize = (EEG_word_level_embeddings - np.mean(EEG_word_level_embeddings)) / np.std(EEG_word_level_embeddings)\n",
    "\n",
    "    float_tensor = torch.tensor(EEG_word_level_embeddings_normalize, dtype=torch.float)\n",
    "    float_tensor = float_tensor.unsqueeze(1)\n",
    "\n",
    "    #print(EEG_word_level_embeddings_normalize)\n",
    "    # Calculate mean and standard deviation\n",
    "    print(torch.isnan(float_tensor).any())\n",
    "\n",
    "    train_data = []\n",
    "    for i in range(len(float_tensor)):\n",
    "       train_data.append([float_tensor[i], Embedded_Word_labels[i]])\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=64)\n",
    "    return trainloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:10.149833Z",
     "end_time": "2024-03-13T15:59:10.217470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word embeddings: 5860\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "Embedded_Word_labels, word_embeddings = create_word_label_embeddings(EEG_word_level_labels)\n",
    "trainloader = create_dataloader(EEG_word_level_embeddings, Embedded_Word_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:10.527451Z",
     "end_time": "2024-03-13T15:59:22.426176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 105, 8]) tensor([[-0.0148,  0.0179, -0.0140,  ..., -0.0073, -0.0057,  0.0152],\n",
      "        [-0.0011,  0.0005,  0.0102,  ...,  0.0192,  0.0100,  0.0185],\n",
      "        [ 0.0102, -0.0174,  0.0052,  ..., -0.0079,  0.0084, -0.0129],\n",
      "        ...,\n",
      "        [-0.0188, -0.0099, -0.0195,  ...,  0.0146,  0.0109,  0.0185],\n",
      "        [ 0.0094,  0.0151, -0.0033,  ..., -0.0023,  0.0073, -0.0118],\n",
      "        [-0.0151,  0.0075, -0.0092,  ...,  0.0195,  0.0127,  0.0070]])\n"
     ]
    }
   ],
   "source": [
    "#sanity check:\n",
    "i1, l1 = next(iter(trainloader))\n",
    "print(i1.shape, l1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.426176Z",
     "end_time": "2024-03-13T15:59:22.473265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "z_size = 100\n",
    "image_size = (105, 8)\n",
    "\n",
    "n_filters = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.473265Z",
     "end_time": "2024-03-13T15:59:22.490508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "## Loss function and optimizers:\n",
    "loss_fn = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.490508Z",
     "end_time": "2024-03-13T15:59:22.568119Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size)*2 - 1\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size)\n",
    "    return input_z\n",
    "\n",
    "mode_z = 'uniform'\n",
    "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "\n",
    "def create_samples(g_model, input_z, input_t):\n",
    "    g_output = g_model(input_z, input_t)\n",
    "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
    "    return (images+1)/2.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.520598Z",
     "end_time": "2024-03-13T15:59:22.588960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "noise = create_noise(64, 100, \"uniform\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.536420Z",
     "end_time": "2024-03-13T15:59:22.589887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 100])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.561103Z",
     "end_time": "2024-03-13T15:59:22.623870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, word_embedding_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.noise_dim = noise_dim\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "\n",
    "        # Define the layers of your generator\n",
    "        self.fc_noise = nn.Linear(noise_dim, 105 * 8)\n",
    "        self.fc_word_embedding = nn.Linear(word_embedding_dim, 105 * 8)\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, noise, word_embedding):\n",
    "        # Process noise\n",
    "        noise = self.fc_noise(noise)\n",
    "        noise = noise.view(noise.size(0), 1, 105, 8)\n",
    "\n",
    "        # Process word embedding\n",
    "        word_embedding = self.fc_word_embedding(word_embedding.to(device))\n",
    "        word_embedding = word_embedding.view(word_embedding.size(0), 1, 105, 8)\n",
    "\n",
    "        #print(\"Word Embedding:\", word_embedding.shape)\n",
    "        # Concatenate noise and word embedding\n",
    "        combined_input = torch.cat([noise, word_embedding], dim=1)\n",
    "\n",
    "        #print(\"Gen Combined Input:\", combined_input.shape)\n",
    "        # Upsample and generate the output\n",
    "        z = self.conv1(combined_input)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv2(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "class DiscriminatorWGAN(nn.Module):\n",
    "    def __init__(self, n_filters, word_embedding_dim):\n",
    "        super(DiscriminatorWGAN, self).__init__()\n",
    "\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.fc_word_embedding = nn.Linear(word_embedding_dim, 105 * 8)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(2, n_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters, n_filters*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(n_filters * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*2, n_filters*4, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(n_filters*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Flatten(),  # Flatten spatial dimensions\n",
    "\n",
    "            # Fully connected layer to reduce to a single value per sample\n",
    "            nn.Linear(n_filters*4 * (105 // 8) * (8 // 8), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input, word_embedding):\n",
    "        word_embedding = self.fc_word_embedding(word_embedding.to(device))\n",
    "        word_embedding = word_embedding.view(word_embedding.size(0), 1, 105, 8)\n",
    "\n",
    "        combined_input = torch.cat([input, word_embedding], dim=1)\n",
    "        #print(\"combined_input:\", combined_input.shape)\n",
    "\n",
    "        output = self.network(combined_input)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.601038Z",
     "end_time": "2024-03-13T15:59:22.710331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "gen_model = Generator(z_size, word_embedding_dim, output_shape).to(device)\n",
    "disc_model = DiscriminatorWGAN(n_filters, word_embedding_dim).to(device)\n",
    "\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.00002)\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.00002)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.663857Z",
     "end_time": "2024-03-13T15:59:22.726014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "def gradient_penalty(real_data, generated_data, input_t):\n",
    "    batch_size = real_data.size(0)\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(real_data.shape[0], 1, 1, 1, requires_grad=True, device=device)\n",
    "    #print(\"Gen:\", generated_data.shape)\n",
    "    interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    proba_interpolated = disc_model(interpolated, input_t)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=proba_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(proba_interpolated.size(), device=device),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradients_norm = gradients.norm(2, dim=1)\n",
    "    return lambda_gp * ((gradients_norm - 1)**2).mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:22.687724Z",
     "end_time": "2024-03-13T15:59:22.726014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "## Train the discriminator\n",
    "def d_train_wgan(x, input_t):\n",
    "\n",
    "    #Init gradient\n",
    "    disc_model.zero_grad()\n",
    "\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    x = x.to(device)\n",
    "\n",
    "    #Discriminating Real Images\n",
    "    d_real = disc_model(x, input_t)\n",
    "\n",
    "    #Building Z\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    #Building Fake T\n",
    "    fake_t = torch.zeros(batch_size, word_embedding_dim).to(device)\n",
    "\n",
    "    #Generating Fake Images\n",
    "    g_output = gen_model(input_z, fake_t)\n",
    "\n",
    "    #Discriminating Fake Images\n",
    "    d_generated = disc_model(g_output, input_t)\n",
    "\n",
    "    d_loss = d_generated.mean() - d_real.mean() + gradient_penalty(x.data, g_output.data, input_t)\n",
    "\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "    return d_loss.data.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:52:09.535776Z",
     "end_time": "2024-03-13T10:52:09.556705Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "## Train the generator\n",
    "def g_train_wgan(x, input_t):\n",
    "\n",
    "    #Init gradient\n",
    "    gen_model.zero_grad()\n",
    "\n",
    "    #Building Z\n",
    "    batch_size = x.size(0)\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "\n",
    "    #Building Fake T\n",
    "    fake_t = torch.zeros(batch_size, word_embedding_dim).to(device)\n",
    "\n",
    "    #Generating Fake Images\n",
    "    g_output = gen_model(input_z, fake_t)\n",
    "\n",
    "    #Discriminating Fake Images\n",
    "    d_generated = disc_model(g_output, fake_t)\n",
    "    g_loss = -d_generated.mean()\n",
    "    #print(\"G Loss:\", g_loss)\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    return g_loss.data.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:52:09.888005Z",
     "end_time": "2024-03-13T10:52:09.888005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "combined_input: torch.Size([64, 2, 105, 8])\n",
      "Gen Combined Input: torch.Size([64, 2, 105, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[178], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (x, t) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trainloader):\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m#print(\"T:\", t.shape)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(critic_iterations):\n\u001B[1;32m---> 16\u001B[0m         d_loss \u001B[38;5;241m=\u001B[39m \u001B[43md_train_wgan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m         \u001B[38;5;66;03m#print(\"D Loss:\", d_loss)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     d_losses\u001B[38;5;241m.\u001B[39mappend(d_loss)\n",
      "Cell \u001B[1;32mIn[176], line 13\u001B[0m, in \u001B[0;36md_train_wgan\u001B[1;34m(x, input_t)\u001B[0m\n\u001B[0;32m     11\u001B[0m d_real \u001B[38;5;241m=\u001B[39m disc_model(x, input_t)\n\u001B[0;32m     12\u001B[0m input_z \u001B[38;5;241m=\u001B[39m create_noise(batch_size, z_size, mode_z)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 13\u001B[0m g_output \u001B[38;5;241m=\u001B[39m \u001B[43mgen_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_z\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#print(\"D Real:\", d_real.shape)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m d_generated \u001B[38;5;241m=\u001B[39m disc_model(g_output, input_t)\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[173], line 34\u001B[0m, in \u001B[0;36mGenerator.forward\u001B[1;34m(self, noise, word_embedding)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Upsample and generate the output\u001B[39;00m\n\u001B[0;32m     33\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(combined_input)\n\u001B[1;32m---> 34\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(z)\n\u001B[0;32m     36\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(z)\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    164\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001B[0m, in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2447\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[0;32m   2448\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[1;32m-> 2450\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2451\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[0;32m   2452\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epoch_samples_wgan = []\n",
    "lambda_gp = 10.0\n",
    "num_epochs = 100\n",
    "torch.manual_seed(1)\n",
    "critic_iterations = 5\n",
    "save_interval = 5\n",
    "checkpoint_path = 'Textual_WGAN_GP_checkpoint_epoch_{}.pth'\n",
    "final_model_path = 'Textual_WGAN_GP_model_final.pth'\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    gen_model.train()\n",
    "    d_losses, g_losses = [], []\n",
    "    for i, (x, t) in enumerate(trainloader):\n",
    "        #print(\"T:\", t.shape)\n",
    "        for _ in range(critic_iterations):\n",
    "            d_loss = d_train_wgan(x, t)\n",
    "            #print(\"D Loss:\", d_loss)\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_train_wgan(x, t))\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | D Loss >>'\n",
    "          f' {torch.FloatTensor(d_losses).mean():.4f}')\n",
    "    print(f'Epoch {epoch:03d} | G Loss >>'\n",
    "          f' {torch.FloatTensor(g_losses).mean():.4f}')\n",
    "\n",
    "        # Save checkpoints at regular intervals\n",
    "    if epoch % save_interval == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'gen_model_state_dict': gen_model.state_dict(),\n",
    "            'optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'd_losses': d_losses,\n",
    "            'g_losses': g_losses,\n",
    "        }, checkpoint_path.format(epoch))\n",
    "\n",
    "\n",
    "    '''\n",
    "    gen_model.eval()\n",
    "    epoch_samples_wgan.append(\n",
    "        create_samples(gen_model, fixed_z, t).detach().cpu().numpy())\n",
    "    '''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Save the final model after training is complete\n",
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'gen_model_state_dict': gen_model.state_dict(),\n",
    "    'optimizer_state_dict': g_optimizer.state_dict(),\n",
    "    'd_losses': d_losses,\n",
    "    'g_losses': g_losses,\n",
    "}, final_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:31:47.058211Z",
     "end_time": "2024-03-13T10:31:47.083532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
