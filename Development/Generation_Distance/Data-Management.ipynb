{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:27:05.674024Z",
     "end_time": "2024-04-12T11:27:06.382345Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# To load the lists from the file:\n",
    "with open(r\"C:\\Users\\gxb18167\\PycharmProjects\\EEG-To-Text\\SIGIR_Development\\EEG-GAN\\EEG_Text_Pairs.pkl\", 'rb') as file:\n",
    "    EEG_word_level_embeddings = pickle.load(file)\n",
    "    EEG_word_level_labels = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:21:16.128449Z",
     "end_time": "2024-04-12T11:21:18.273032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#create dictionary with words a labels and the EEG embeddings in a list as the values\n",
    "\n",
    "EEG_word_level_dict = {}\n",
    "for i in range(len(EEG_word_level_labels)):\n",
    "    if EEG_word_level_labels[i] in EEG_word_level_dict:\n",
    "        EEG_word_level_dict[EEG_word_level_labels[i]].append(EEG_word_level_embeddings[i])\n",
    "    else:\n",
    "        EEG_word_level_dict[EEG_word_level_labels[i]] = [EEG_word_level_embeddings[i]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:22:32.705215Z",
     "end_time": "2024-04-12T11:22:32.720945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def average_eeg_segments(eeg_segments):\n",
    "    \"\"\"\n",
    "    Compute the average EEG segment from a list of EEG segments.\n",
    "\n",
    "    Parameters:\n",
    "        eeg_segments (list of array-like): List of EEG segment data.\n",
    "\n",
    "    Returns:\n",
    "        array-like: Average EEG segment.\n",
    "    \"\"\"\n",
    "    # Stack EEG segments along a new axis to compute the average\n",
    "    stacked_segments = np.stack(eeg_segments, axis=0)\n",
    "\n",
    "    # Compute the mean across segments\n",
    "    avg_segment = np.mean(stacked_segments, axis=0)\n",
    "\n",
    "    return avg_segment\n",
    "\n",
    "# Example usage\n",
    "# Assuming eeg_segments_dict is a dictionary where keys are words and values are lists of EEG segments\n",
    "\n",
    "# Dictionary containing average EEG segment for each word\n",
    "average_segments_dict = {}\n",
    "\n",
    "for word, segments in EEG_word_level_dict.items():\n",
    "    # Compute average EEG segment for the current word\n",
    "    avg_segment = average_eeg_segments(segments)\n",
    "\n",
    "    # Store average segment in dictionary\n",
    "    average_segments_dict[word] = avg_segment"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:32:33.072915Z",
     "end_time": "2024-04-12T11:32:33.706256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:32:47.765468Z",
     "end_time": "2024-04-12T11:32:47.787889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def convert_to_probability_distribution(eeg_segment):\n",
    "    \"\"\"\n",
    "    Convert EEG segment to a probability distribution.\n",
    "\n",
    "    Parameters:\n",
    "        eeg_segment (array-like): EEG segment data.\n",
    "\n",
    "    Returns:\n",
    "        array-like: Probability distribution representing the EEG segment.\n",
    "    \"\"\"\n",
    "    # Resize EEG segment to a 1D array\n",
    "    flattened_segment = eeg_segment.ravel()\n",
    "\n",
    "    # Normalize the flattened segment\n",
    "    normalized_segment = (flattened_segment - np.mean(flattened_segment)) / np.std(flattened_segment)\n",
    "\n",
    "    # Convert normalized segment into probability values\n",
    "    # For example, you can apply softmax function\n",
    "    probabilities = np.exp(normalized_segment) / np.sum(np.exp(normalized_segment))\n",
    "\n",
    "    return probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:32:51.454553Z",
     "end_time": "2024-04-12T11:32:51.470496Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "probability_distribution_dict = {}\n",
    "\n",
    "for word, segment in average_segments_dict.items():\n",
    "    probability_distribution_dict[word] = convert_to_probability_distribution(segment)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:22:40.815461Z",
     "end_time": "2024-04-12T12:22:41.328380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:22:55.097144Z",
     "end_time": "2024-04-12T12:22:55.128665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def compute_js_distance(p, q):\n",
    "    \"\"\"\n",
    "    Compute Jensen-Shannon distance between two probability distributions.\n",
    "\n",
    "    Parameters:\n",
    "        p (array-like): Probability distribution.\n",
    "        q (array-like): Probability distribution.\n",
    "\n",
    "    Returns:\n",
    "        float: Jensen-Shannon distance between distributions.\n",
    "    \"\"\"\n",
    "    # Normalize distributions\n",
    "    p = p / np.sum(p)\n",
    "    q = q / np.sum(q)\n",
    "\n",
    "    # Compute average distribution\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # Compute Jensen-Shannon divergence\n",
    "    js_divergence = 0.5 * (distance.jensenshannon(p, m) + distance.jensenshannon(q, m))\n",
    "\n",
    "    return js_divergence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:45:38.251119Z",
     "end_time": "2024-04-12T11:45:38.272297Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "#Random example\n",
    "# Compute Jensen-Shannon distance between two probability distributions\n",
    "\n",
    "random_distance_dict = {}\n",
    "\n",
    "for word, segment in probability_distribution_dict.items():\n",
    "\n",
    "\n",
    "    mean_eeg = np.mean(average_segments_dict[word])\n",
    "    std_dev_eeg = np.std(average_segments_dict[word])\n",
    "\n",
    "    random_value = np.random.normal(loc=mean_eeg, scale=std_dev_eeg, size=average_segments_dict[word].shape)\n",
    "    random_value = convert_to_probability_distribution(random_value)\n",
    "\n",
    "    js_distance = compute_js_distance(segment, random_value)\n",
    "    random_distance_dict[word] = js_distance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:26:07.834951Z",
     "end_time": "2024-04-12T12:26:09.187677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:26:28.116429Z",
     "end_time": "2024-04-12T12:26:28.116429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gxb18167\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def create_word_label_embeddings(Word_Labels_List):\n",
    "    tokenized_words = []\n",
    "    for i in range(len(Word_Labels_List)):\n",
    "        tokenized_words.append([Word_Labels_List[i]])\n",
    "    model = Word2Vec(sentences=tokenized_words, vector_size=50, window=5, min_count=1, workers=4)\n",
    "    word_embeddings = {word: model.wv[word] for word in model.wv.index_to_key}\n",
    "    print(\"Number of word embeddings:\", len(word_embeddings))\n",
    "\n",
    "    Embedded_Word_labels = []\n",
    "    for word in EEG_word_level_labels:\n",
    "        Embedded_Word_labels.append(word_embeddings[word])\n",
    "\n",
    "    return Embedded_Word_labels, word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:32:02.924170Z",
     "end_time": "2024-04-12T12:32:06.356668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word embeddings: 5860\n"
     ]
    }
   ],
   "source": [
    "Embedded_Word_labels, word_embeddings = create_word_label_embeddings(EEG_word_level_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:32:41.965253Z",
     "end_time": "2024-04-12T12:32:43.132064Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:33:43.853616Z",
     "end_time": "2024-04-12T12:33:43.872886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T11:55:49.003070Z",
     "end_time": "2024-04-12T11:55:49.019106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T12:26:43.139979Z",
     "end_time": "2024-04-12T12:26:43.155979Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
