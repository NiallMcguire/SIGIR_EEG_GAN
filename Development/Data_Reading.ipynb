{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-14T16:24:30.990869Z",
     "end_time": "2023-11-14T16:24:33.465818Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Preprocessing import *\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size)*2 - 1\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size)\n",
    "    return input_z"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:14.569837Z",
     "end_time": "2023-11-14T17:07:14.584202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "noise = create_noise(64, 100, 'normal')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:14.749648Z",
     "end_time": "2023-11-14T17:07:14.776134Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 100])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:15.021423Z",
     "end_time": "2023-11-14T17:07:15.036272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Output Shape: torch.Size([64, 1, 105, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        # Define your layers here\n",
    "        self.fc = nn.Linear(latent_dim, 1 * 105 * 8)\n",
    "        self.conv_transpose = nn.ConvTranspose2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Reshape the input\n",
    "        x = self.fc(z)\n",
    "        x = x.view(-1, 1, 105, 8)\n",
    "\n",
    "        # Apply convolutional transpose layer\n",
    "        x = self.conv_transpose(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "latent_dim = 100\n",
    "output_shape = (64, 1, 105, 8)\n",
    "\n",
    "# Create an instance of the generator\n",
    "generator = Generator(latent_dim, output_shape)\n",
    "\n",
    "# Generate a random input\n",
    "z = torch.randn((64, latent_dim))\n",
    "\n",
    "# Forward pass to generate an output\n",
    "output = generator(noise)\n",
    "\n",
    "print(\"Generator Output Shape:\", output.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:20.806095Z",
     "end_time": "2023-11-14T17:07:20.853880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 105, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.noise_dim = noise_dim\n",
    "\n",
    "        # Define the layers of your generator\n",
    "        self.fc = nn.Linear(noise_dim, 105 * 8)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Reshape the noise vector\n",
    "        z = self.fc(z)\n",
    "        z = z.view(z.size(0), 1, 105, 8)\n",
    "\n",
    "        # Upsample and generate the output\n",
    "        z = self.conv1(z)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv2(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "# Example usage\n",
    "noise_dim = 100  # Adjust the noise dimension as needed\n",
    "output_shape = (1, 105, 8)\n",
    "batch_size = 64  # Adjust the batch size as needed\n",
    "\n",
    "# Create an instance of the generator\n",
    "generator = Generator(noise_dim, output_shape)\n",
    "\n",
    "# Generate random noise\n",
    "noise = torch.randn(batch_size, noise_dim)\n",
    "\n",
    "# Generate fake data\n",
    "fake_data = generator(noise)\n",
    "\n",
    "# Check the shape of the generated data\n",
    "print(fake_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T10:12:14.808626Z",
     "end_time": "2023-11-15T10:12:14.854191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 105, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, word_embedding_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.noise_dim = noise_dim\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "\n",
    "        # Define the layers of your generator\n",
    "        self.fc_noise = nn.Linear(noise_dim, 105 * 8)\n",
    "        self.fc_word_embedding = nn.Linear(word_embedding_dim, 105 * 8)\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, noise, word_embedding):\n",
    "        # Process noise\n",
    "        noise = self.fc_noise(noise)\n",
    "        noise = noise.view(noise.size(0), 1, 105, 8)\n",
    "\n",
    "        # Process word embedding\n",
    "        word_embedding = self.fc_word_embedding(word_embedding)\n",
    "        word_embedding = word_embedding.view(word_embedding.size(0), 1, 105, 8)\n",
    "\n",
    "        # Concatenate noise and word embedding\n",
    "        combined_input = torch.cat([noise, word_embedding], dim=1)\n",
    "\n",
    "        # Upsample and generate the output\n",
    "        z = self.conv1(combined_input)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv2(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "# Example usage\n",
    "noise_dim = 100  # Adjust the noise dimension as needed\n",
    "word_embedding_dim = 50  # Adjust the word embedding dimension as needed\n",
    "output_shape = (1, 105, 8)\n",
    "batch_size = 16  # Adjust the batch size as needed\n",
    "\n",
    "# Create an instance of the generator\n",
    "generator = Generator(noise_dim, word_embedding_dim, output_shape)\n",
    "\n",
    "# Generate random noise and word embedding\n",
    "noise = torch.randn(batch_size, noise_dim)\n",
    "word_embedding = torch.randn(batch_size, word_embedding_dim)\n",
    "\n",
    "# Generate fake data\n",
    "fake_data = generator(noise, word_embedding)\n",
    "\n",
    "# Check the shape of the generated data\n",
    "print(fake_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T10:14:13.464602Z",
     "end_time": "2023-11-15T10:14:13.534054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 100])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T16:42:20.129903Z",
     "end_time": "2023-11-14T16:42:20.138562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def data_structure(raw):\n",
    "    sampling_freq = raw.info['sfreq']\n",
    "    start_end_secs = np.array([0,4850]) # Fro this dataset data start at 0.000 and end at 4840.166 secs\n",
    "    start_sample, stop_sample = (start_end_secs * sampling_freq).astype(int)\n",
    "    df = raw.to_data_frame(picks=['all'], start=start_sample, stop=stop_sample)\n",
    "    # then save using df.to_csv(...), df.to_hdf(...), etc\n",
    "\n",
    "    df = df.drop(['time', \"STI 014\"], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:39.722385Z",
     "end_time": "2023-10-13T15:10:39.724865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def create_rolling_window(data, window_size=5):\n",
    "    \"\"\"\n",
    "    This function creates a rolling window of a given size from a data frame.\n",
    "    It assigns the majority label to the window.\n",
    "\n",
    "    Creator : Niall\n",
    "\n",
    "    Args:\n",
    "        data: Dataframe to be windowed\n",
    "        window_size: The size of the window to be created\n",
    "\n",
    "    Returns:\n",
    "        windows: A list of dataframes containing the windows\n",
    "        labels: A list of labels corresponding to the windows\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    windows = []\n",
    "    labels = []\n",
    "    data = data.to_numpy()\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        window_data = data[i:i + window_size]\n",
    "        label = window_data[:, -1][0]  # Assign majority label\n",
    "        labels.append(label)\n",
    "        window_data = window_data[:, :-1]\n",
    "        windows.append(window_data)\n",
    "\n",
    "    return windows, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:39.724865Z",
     "end_time": "2023-10-13T15:10:39.733793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:39.735777Z",
     "end_time": "2023-10-13T15:10:39.742721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\niall\\Desktop\\PhD\\OpenMIIR-RawEEG_v1\\P04-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 2480032 =      0.000 ...  4843.812 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw = import_data(r\"C:\\Users\\niall\\Desktop\\PhD\\OpenMIIR-RawEEG_v1\\P04-raw.fif\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:40.256081Z",
     "end_time": "2023-10-13T15:10:40.425217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "df = data_structure(raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:41.009505Z",
     "end_time": "2023-10-13T15:10:47.761055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "windows, labels = create_rolling_window(df, window_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:47.766015Z",
     "end_time": "2023-10-13T15:10:50.016863Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "data_list = windows[:200]  # Replace with your actual data\n",
    "\n",
    "# Convert the list of arrays to PyTorch tensors\n",
    "data_tensors = [torch.Tensor(array) for array in data_list]\n",
    "\n",
    "# Stack the tensors to create a 3D tensor (200x5x67)\n",
    "data_tensor = torch.stack(data_tensors, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:50.019343Z",
     "end_time": "2023-10-13T15:10:50.074399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "shuffle = True   # You can set this to True if you want to shuffle the data\n",
    "\n",
    "dataset = CustomDataset(data_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:50.074895Z",
     "end_time": "2023-10-13T15:10:50.359599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([8, 5, 67])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.shape)\n",
    "    # Do stuff with the batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T14:56:50.242930Z",
     "end_time": "2023-10-13T14:56:50.272194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T14:58:31.194282Z",
     "end_time": "2023-10-13T14:58:31.206186Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def make_discriminator_network(\n",
    "        input_size,\n",
    "        num_hidden_layers=1,\n",
    "        num_hidden_units=100,\n",
    "        num_output_units=1\n",
    "):\n",
    "    model = nn.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add_module(\n",
    "            f'fc_d{i}',\n",
    "            nn.Linear(input_size, num_hidden_units, bias=False)\n",
    "        )\n",
    "        model.add_module(f'relu_d{i}', nn.LeakyReLU())\n",
    "        model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "        input_size = num_hidden_units\n",
    "    model.add_module(f'fc_d{num_hidden_layers}',\n",
    "                     nn.Linear(input_size, num_output_units))\n",
    "    model.add_module('sigmoid', nn.Sigmoid())\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T14:57:06.154111Z",
     "end_time": "2023-10-13T14:57:06.160558Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "disc_model = make_discriminator_network(\n",
    "    input_size=335,\n",
    "    num_hidden_layers=1,\n",
    "    num_hidden_units=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:29.488227Z",
     "end_time": "2023-10-13T15:17:29.496658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc_d0): Linear(in_features=335, out_features=32, bias=False)\n",
      "  (relu_d0): LeakyReLU(negative_slope=0.01)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc_d1): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(disc_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:30.064578Z",
     "end_time": "2023-10-13T15:17:30.068546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "input_real = next(iter(dataloader))\n",
    "input_real = input_real.view(batch_size, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:30.068050Z",
     "end_time": "2023-10-13T15:17:30.075986Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 335])"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_real.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:30.077474Z",
     "end_time": "2023-10-13T15:17:30.083922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "d_proba_real = disc_model(input_real)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:34.106481Z",
     "end_time": "2023-10-13T15:17:34.114417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]], grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_proba_real"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:34.665970Z",
     "end_time": "2023-10-13T15:17:34.697219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_proba_real.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:35.561746Z",
     "end_time": "2023-10-13T15:17:35.569681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
