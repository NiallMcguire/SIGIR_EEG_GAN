{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-14T16:24:30.990869Z",
     "end_time": "2023-11-14T16:24:33.465818Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Preprocessing import *\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size)*2 - 1\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size)\n",
    "    return input_z"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:14.569837Z",
     "end_time": "2023-11-14T17:07:14.584202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "noise = create_noise(64, 100, 'normal')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:14.749648Z",
     "end_time": "2023-11-14T17:07:14.776134Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 100])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:15.021423Z",
     "end_time": "2023-11-14T17:07:15.036272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Output Shape: torch.Size([64, 1, 105, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        # Define your layers here\n",
    "        self.fc = nn.Linear(latent_dim, 1 * 105 * 8)\n",
    "        self.conv_transpose = nn.ConvTranspose2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Reshape the input\n",
    "        x = self.fc(z)\n",
    "        x = x.view(-1, 1, 105, 8)\n",
    "\n",
    "        # Apply convolutional transpose layer\n",
    "        x = self.conv_transpose(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "latent_dim = 100\n",
    "output_shape = (64, 1, 105, 8)\n",
    "\n",
    "# Create an instance of the generator\n",
    "generator = Generator(latent_dim, output_shape)\n",
    "\n",
    "# Generate a random input\n",
    "z = torch.randn((64, latent_dim))\n",
    "\n",
    "# Forward pass to generate an output\n",
    "output = generator(noise)\n",
    "\n",
    "print(\"Generator Output Shape:\", output.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T17:07:20.806095Z",
     "end_time": "2023-11-14T17:07:20.853880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 105, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.noise_dim = noise_dim\n",
    "\n",
    "        # Define the layers of your generator\n",
    "        self.fc = nn.Linear(noise_dim, 105 * 8)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Reshape the noise vector\n",
    "        z = self.fc(z)\n",
    "        z = z.view(z.size(0), 1, 105, 8)\n",
    "\n",
    "        # Upsample and generate the output\n",
    "        z = self.conv1(z)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv2(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "# Example usage\n",
    "noise_dim = 100  # Adjust the noise dimension as needed\n",
    "output_shape = (1, 105, 8)\n",
    "batch_size = 64  # Adjust the batch size as needed\n",
    "\n",
    "# Create an instance of the generator\n",
    "generator = Generator(noise_dim, output_shape)\n",
    "\n",
    "# Generate random noise\n",
    "noise = torch.randn(batch_size, noise_dim)\n",
    "\n",
    "# Generate fake data\n",
    "fake_data = generator(noise)\n",
    "\n",
    "# Check the shape of the generated data\n",
    "print(fake_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T10:12:14.808626Z",
     "end_time": "2023-11-15T10:12:14.854191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 105, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, word_embedding_dim, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.noise_dim = noise_dim\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "\n",
    "        # Define the layers of your generator\n",
    "        self.fc_noise = nn.Linear(noise_dim, 105 * 8)\n",
    "        self.fc_word_embedding = nn.Linear(word_embedding_dim, 105 * 8)\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, noise, word_embedding):\n",
    "        # Process noise\n",
    "        noise = self.fc_noise(noise)\n",
    "        noise = noise.view(noise.size(0), 1, 105, 8)\n",
    "\n",
    "        # Process word embedding\n",
    "        word_embedding = self.fc_word_embedding(word_embedding)\n",
    "        word_embedding = word_embedding.view(word_embedding.size(0), 1, 105, 8)\n",
    "\n",
    "        # Concatenate noise and word embedding\n",
    "        combined_input = torch.cat([noise, word_embedding], dim=1)\n",
    "\n",
    "        # Upsample and generate the output\n",
    "        z = self.conv1(combined_input)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv2(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "# Example usage\n",
    "noise_dim = 100  # Adjust the noise dimension as needed\n",
    "word_embedding_dim = 50  # Adjust the word embedding dimension as needed\n",
    "output_shape = (1, 105, 8)\n",
    "batch_size = 16  # Adjust the batch size as needed\n",
    "\n",
    "# Create an instance of the generator\n",
    "generator = Generator(noise_dim, word_embedding_dim, output_shape)\n",
    "\n",
    "# Generate random noise and word embedding\n",
    "noise = torch.randn(batch_size, noise_dim)\n",
    "word_embedding = torch.randn(batch_size, word_embedding_dim)\n",
    "\n",
    "# Generate fake data\n",
    "fake_data = generator(noise, word_embedding)\n",
    "\n",
    "# Check the shape of the generated data\n",
    "print(fake_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T11:50:59.561580Z",
     "end_time": "2023-11-20T11:51:01.897078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gxb18167\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: words, Embedding: [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
      "Word: of, Embedding: [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
      "Word: list, Embedding: [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
      "  7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
      " -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
      "  9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
      "  5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
      " -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
      "  7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
      " -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
      " -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
      " -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
      " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
      "  3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
      " -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
      " -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
      " -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
      "  4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
      " -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
      " -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
      "  4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
      "  9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
      "  1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
      "  1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
      "  8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
      "  9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
      "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
      "Word: example, Embedding: [-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
      "  4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
      "  6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
      "  3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
      "  8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
      "  1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
      " -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
      "  2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
      " -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
      "  9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
      "  3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
      "  7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
      " -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
      " -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
      "  1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
      "  2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
      "  4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
      " -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
      " -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
      " -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
      " -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
      " -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
      " -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
      " -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
      "  5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize  # You might need to install nltk: pip install nltk\n",
    "\n",
    "# Example list of words\n",
    "word_list = [\"example\", \"list\", \"of\", \"words\"]\n",
    "\n",
    "# Tokenize the words\n",
    "tokenized_words = [word_tokenize(word) for word in word_list]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_words, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get the word embeddings\n",
    "word_embeddings = {word: model.wv[word] for word in model.wv.index_to_key}\n",
    "\n",
    "# Example usage\n",
    "for word, embedding in word_embeddings.items():\n",
    "    print(f\"Word: {word}, Embedding: {embedding}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T13:43:37.517902Z",
     "end_time": "2023-11-15T13:43:39.012250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def data_structure(raw):\n",
    "    sampling_freq = raw.info['sfreq']\n",
    "    start_end_secs = np.array([0,4850]) # Fro this dataset data start at 0.000 and end at 4840.166 secs\n",
    "    start_sample, stop_sample = (start_end_secs * sampling_freq).astype(int)\n",
    "    df = raw.to_data_frame(picks=['all'], start=start_sample, stop=stop_sample)\n",
    "    # then save using df.to_csv(...), df.to_hdf(...), etc\n",
    "\n",
    "    df = df.drop(['time', \"STI 014\"], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:39.722385Z",
     "end_time": "2023-10-13T15:10:39.724865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def create_rolling_window(data, window_size=5):\n",
    "    \"\"\"\n",
    "    This function creates a rolling window of a given size from a data frame.\n",
    "    It assigns the majority label to the window.\n",
    "\n",
    "    Creator : Niall\n",
    "\n",
    "    Args:\n",
    "        data: Dataframe to be windowed\n",
    "        window_size: The size of the window to be created\n",
    "\n",
    "    Returns:\n",
    "        windows: A list of dataframes containing the windows\n",
    "        labels: A list of labels corresponding to the windows\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    windows = []\n",
    "    labels = []\n",
    "    data = data.to_numpy()\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        window_data = data[i:i + window_size]\n",
    "        label = window_data[:, -1][0]  # Assign majority label\n",
    "        labels.append(label)\n",
    "        window_data = window_data[:, :-1]\n",
    "        windows.append(window_data)\n",
    "\n",
    "    return windows, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:39.724865Z",
     "end_time": "2023-10-13T15:10:39.733793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:39.735777Z",
     "end_time": "2023-10-13T15:10:39.742721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\niall\\Desktop\\PhD\\OpenMIIR-RawEEG_v1\\P04-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 2480032 =      0.000 ...  4843.812 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw = import_data(r\"C:\\Users\\niall\\Desktop\\PhD\\OpenMIIR-RawEEG_v1\\P04-raw.fif\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:40.256081Z",
     "end_time": "2023-10-13T15:10:40.425217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "df = data_structure(raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:41.009505Z",
     "end_time": "2023-10-13T15:10:47.761055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "windows, labels = create_rolling_window(df, window_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:47.766015Z",
     "end_time": "2023-10-13T15:10:50.016863Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "data_list = windows[:200]  # Replace with your actual data\n",
    "\n",
    "# Convert the list of arrays to PyTorch tensors\n",
    "data_tensors = [torch.Tensor(array) for array in data_list]\n",
    "\n",
    "# Stack the tensors to create a 3D tensor (200x5x67)\n",
    "data_tensor = torch.stack(data_tensors, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:50.019343Z",
     "end_time": "2023-10-13T15:10:50.074399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "shuffle = True   # You can set this to True if you want to shuffle the data\n",
    "\n",
    "dataset = CustomDataset(data_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:10:50.074895Z",
     "end_time": "2023-10-13T15:10:50.359599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([32, 5, 67])\n",
      "torch.Size([8, 5, 67])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.shape)\n",
    "    # Do stuff with the batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T14:56:50.242930Z",
     "end_time": "2023-10-13T14:56:50.272194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T14:58:31.194282Z",
     "end_time": "2023-10-13T14:58:31.206186Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def make_discriminator_network(\n",
    "        input_size,\n",
    "        num_hidden_layers=1,\n",
    "        num_hidden_units=100,\n",
    "        num_output_units=1\n",
    "):\n",
    "    model = nn.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add_module(\n",
    "            f'fc_d{i}',\n",
    "            nn.Linear(input_size, num_hidden_units, bias=False)\n",
    "        )\n",
    "        model.add_module(f'relu_d{i}', nn.LeakyReLU())\n",
    "        model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "        input_size = num_hidden_units\n",
    "    model.add_module(f'fc_d{num_hidden_layers}',\n",
    "                     nn.Linear(input_size, num_output_units))\n",
    "    model.add_module('sigmoid', nn.Sigmoid())\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T14:57:06.154111Z",
     "end_time": "2023-10-13T14:57:06.160558Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "disc_model = make_discriminator_network(\n",
    "    input_size=335,\n",
    "    num_hidden_layers=1,\n",
    "    num_hidden_units=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:29.488227Z",
     "end_time": "2023-10-13T15:17:29.496658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc_d0): Linear(in_features=335, out_features=32, bias=False)\n",
      "  (relu_d0): LeakyReLU(negative_slope=0.01)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc_d1): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(disc_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:30.064578Z",
     "end_time": "2023-10-13T15:17:30.068546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "input_real = next(iter(dataloader))\n",
    "input_real = input_real.view(batch_size, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:30.068050Z",
     "end_time": "2023-10-13T15:17:30.075986Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 335])"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_real.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:30.077474Z",
     "end_time": "2023-10-13T15:17:30.083922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "d_proba_real = disc_model(input_real)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:34.106481Z",
     "end_time": "2023-10-13T15:17:34.114417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]], grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_proba_real"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:34.665970Z",
     "end_time": "2023-10-13T15:17:34.697219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_proba_real.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T15:17:35.561746Z",
     "end_time": "2023-10-13T15:17:35.569681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
